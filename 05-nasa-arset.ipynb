{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA Trainee (Riga) - Mapping Crops and their Biophysical Characteristics with Polarimetric SAR and Optical Remote Sensing\n",
    "\n",
    "Practical Wedneseday 29th June 2022: Crop specific time series analysis for growth monitoring\n",
    "\n",
    "Prepared by UCLouvain-Geomatics\n",
    "\n",
    "Adapted for the Agriculture Virtual Laboratory by Brockmann Consult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction & guidelines\n",
    "\n",
    "This Jupyter-notebook allows to exploit the Sentinel-2 Leaf Area Index (LAI) time-series produced in the previous section of this training module using the SNAP software. The first step of this section corresponds to a quality control procedure and aims to detect and potentially remove any image showing outliers or marginal surface reflectance from the image time series. The second step investigates the respective temporal profiles of all corn fields of the study area, classifies their growing patterns over the season, and their corresponding intra-parcel heterogeneity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and packages\n",
    "\n",
    "This notebook runs without further package installation on the Agriculture Virtual Laboratory with any AVL user environment from version 1.1.5 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package importation\n",
    "\n",
    "First the  required packages must be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import rasterio\n",
    "import plotly.express as px\n",
    "from rasterio.plot import show\n",
    "import glob, os, time\n",
    "import folium\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import earthpy\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "from pyproj import Transformer\n",
    "import contextily as cx\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import s3fs\n",
    "\n",
    "print(\"All the packages are imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `glob` function to find input data in object storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3filesystem = s3fs.S3FileSystem(anon=False)\n",
    "def glob(globexpr: str) -> list[str]:\n",
    "    return ['s3://' + path for path in s3filesystem.glob(globexpr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a directory to store working files and output data during notebook execution, and make sure that it exists. Data written to this directory can be viewed and downloaded in the JupyterLab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.expanduser('~/arset-output/')\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation of vector and raster data used in the notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing steps\n",
    "\n",
    "All the Sentinel-2 images (2020 time series for the T31UFS tile) bands 2, 3, 4 and 8 (Blue, Green, Red and Near infrared) have been preprocessed using SNAP and cropped to the region of interest in order to reduce the computation time and the weight of the files included in this notebook. \n",
    "\n",
    "If the Sentinel-2 LAI images produced using SNAP as explained in the previous section are not available to you for any reason, you might use the so called ‘backup_training_data’ to continue with this Jupyter Notebook, found on the ARSET training page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Specification of the paths to the files used in this notebook\n",
    "\n",
    "The ```work_path``` variable is the path where the folder containing the data is located. For the AVL version of the notebook, this variable is set to reference the required data in AVL’s object storage.\n",
    "\n",
    "Once the required path is specified, a list of the paths to the single-bands tifs (red,green,blue and Near infrared bands) in the folder is created using the ```glob``` function.\n",
    "The shapefile containing the parcels which will be analysed is also loaded in a geoDataFrame which is a data-structure similar to a pandas dataframe with an added geographic attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = 's3://agriculture-vlab-data/ARSET/Training_data/'\n",
    "\n",
    "vector_path = f\"{work_path}shp\"\n",
    "bands_path  = f\"{work_path}images\"\n",
    "lai_path    = f\"{work_path}images\"\n",
    "\n",
    "blue_list  = sorted(glob(f\"{bands_path}/*.data/B2.img\"))\n",
    "green_list = sorted(glob(f\"{bands_path}/*.data/B3.img\"))\n",
    "red_list   = sorted(glob(f\"{bands_path}/*.data/B4.img\"))\n",
    "nir_list   = sorted(glob(f\"{bands_path}/*.data/B8.img\"))\n",
    "lai_list = sorted(glob(f\"{bands_path}/*.data/lai.img\"))\n",
    "\n",
    "\n",
    "print(f'The image list of red bands contains {len(red_list)} images ')\n",
    "print(f'The image list of green bands contains {len(green_list)} images ')\n",
    "print(f'The image list of blue bands contains {len(blue_list)} images ')\n",
    "print(f'The image list of near infra-red bands contains {len(nir_list)} images ')\n",
    "\n",
    "invariant_shp_path = f\"{vector_path}/invariant_shp/invariant_surfaces.shp\"\n",
    "invariant_gdf = geopandas.read_file(invariant_shp_path)\n",
    "invariant_gdf = invariant_gdf.to_crs(\"epsg:32631\")\n",
    "\n",
    "print(f'The crs of the invariant surfaces shapefile is {invariant_gdf.crs}')\n",
    "\n",
    "\n",
    "roi_gdf = geopandas.read_file(f\"{vector_path}/crop_shp/all_crops_clipped_to_extent_english.shp\")\n",
    "roi_gdf = roi_gdf.set_crs('epsg:32631')\n",
    "bands   = ['B2','B3','B4','B8']\n",
    "#display(roi_gdf)\n",
    "print(f'The crs of the maize shapefile is {roi_gdf.crs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Time series analysis: outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualization of the selected invariant targets (polygons) in the region of interest\n",
    "\n",
    "The contextily package allows to display shapefiles overlaying basemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax,axs) = plt.subplots(1,2,figsize=(15, 15))\n",
    "\n",
    "# Plot the invariant target on a basemap\n",
    "ax.set_title(\"Visualization of the invariant target polygons\", fontsize=15,y = 1)\n",
    "invariant_gdf.plot(ax=ax, facecolor=None, edgecolor=\"white\", alpha=1, lw=1, column='TYPE', legend = True, legend_kwds={'loc': 'upper left'})\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldImagery, crs=invariant_gdf.crs.to_string())\n",
    "\n",
    "# Create a bbox (=extent polygon) containing the invariant targets\n",
    "extent_invariant = box(*invariant_gdf.geometry.total_bounds)\n",
    "extent_invariant_gdf = geopandas.GeoDataFrame(index=[0], crs=\"epsg:32631\", geometry=[extent_invariant])\n",
    "\n",
    "# Plot the extent on  a basemap\n",
    "axs.set_title('Shapefile of invariant surfaces extent')\n",
    "extent_invariant_gdf.plot(ax = axs, facecolor=\"none\", edgecolor=\"red\", linewidth=4)\n",
    "cx.add_basemap(axs, source=cx.providers.OpenStreetMap.Mapnik, crs=extent_invariant_gdf.crs.to_string())\n",
    "\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of surface reflectance images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of cloud-free RGB-image with a cloudy one \n",
    "\n",
    "Using the red, green, and blue bands of the images, true color composites can be plotted and clear and cloudy images can be compared. The earthpy library has a convenient function to do so and is used in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb_list_clear = [sorted(red_list)[5], sorted(green_list)[5], sorted(blue_list)[5]]\n",
    "\n",
    "rgb_array = []\n",
    "\n",
    "for image in rgb_list_clear:\n",
    "    with rasterio.open(image) as src:\n",
    "        out_image = src.read(1)\n",
    "        rgb_array.append(out_image)\n",
    "        \n",
    "rgb_stack = np.array(rgb_array)\n",
    "\n",
    "fig, (ax,axs) = plt.subplots(1,2,figsize=(15, 7))\n",
    "\n",
    "ep.plot_rgb(\n",
    "    rgb_stack,\n",
    "    rgb=(0, 1, 2),\n",
    "    ax=ax,\n",
    "    title=\"Cloud-free Sentinel-2 RGB image clipped to the extent of the region of interest \",\n",
    "    stretch=True,\n",
    "    )\n",
    "\n",
    "rgb_list_cloudy = [sorted(red_list)[1], sorted(green_list)[1], sorted(blue_list)[1]]\n",
    "rgb_array = []\n",
    "\n",
    "for image in rgb_list_cloudy:\n",
    "    with rasterio.open(image) as src:\n",
    "        out_image = src.read(1)\n",
    "        rgb_array.append(out_image)\n",
    "        \n",
    "rgb_stack = np.array(rgb_array)\n",
    "\n",
    "\n",
    "ep.plot_rgb(\n",
    "    rgb_stack,\n",
    "    rgb=(0, 1, 2),\n",
    "    ax=axs,\n",
    "    title=\"Cloudy Sentinel-2 RGB image clipped to the extent of the region of interest \",\n",
    "    stretch=True,\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Optional part: Use of Sen2Cor to mask clouds \n",
    "\n",
    "This section is for information purposes only and is intended to show how to mask clouds using sen2cor masks. The images used in this notebook are cloud-free and thus don't need to be masked.\n",
    "\n",
    "## Creation of the folders that will contain the cloud-masked bands\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for band in bands[:-1]:\n",
    "    masked_path = f'{bands_path}_MASKED_SEN2COR_DA'\n",
    "    if not os.path.isfile(masked_path):\n",
    "        Path(masked_path).mkdir(parents=True, exist_ok=True)\n",
    "        print(f'the masked bands folder of {band} has been created')\n",
    "    else:\n",
    "        print('the masked paths already exists')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of the Sen2Cor mask on the bands\n",
    "\n",
    "The cloudy pixels are removed using the Masks from the cloud mask rasters. Here all the values in this raster that are not equal to 2,4,5,6 or 7 indicate that the corresponding pixels have to be masked. Each image of the mask list is thus reclassified to create binary rasters where 0 represents good pixels and 1 represents pixels to be masked out. \n",
    "\n",
    "The values of the mask are classes assigned by the algorithm and correspond to:\n",
    "\n",
    "* 0 : No-data\n",
    "* 1 : Saturated or defective pixel\n",
    "* 2 : Dark area pixel\n",
    "* 3 : Cloud shadows\n",
    "* 4 : Vegetation\n",
    "* 5 : Not vegetated\n",
    "* 6 : Water\n",
    "* 7 : Unclassified\n",
    "* 8 : Cloud medium probability\n",
    "* 9 : Cloud high probability\n",
    "* 10 : Thin cirrus\n",
    "* 11 : Snow\n",
    "\n",
    "This new binary mask list is used to mask all the unusable pixels detected by Sen2Cors on each band of the rasters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nodata_val = -10000\n",
    "\n",
    "for band in bands[:-1]:\n",
    "    im_list = sorted(glob(f\"{rasters_path}{band}/*.tif\"))\n",
    "\n",
    "    for im_file in im_list:\n",
    "\n",
    "        # Get date of image\n",
    "        date = os.path.basename(im_file)[7 : 7 + 9]\n",
    "\n",
    "        # Find SCL corresponding to the given reflectances image\n",
    "        scl_file = glob(f\"{rasters_path}MASKS/*{date}.tif\")[0]\n",
    "\n",
    "        scl_file = scl_file.replace(\"\\\\\", \"/\")\n",
    "\n",
    "        im_file_scl = (\n",
    "            f\"{rasters_path}{band}_MASKED_SEN2COR_DA/{os.path.basename(im_file)[:-4]}_SCL.tif\"\n",
    "        )\n",
    "\n",
    "        if not os.path.isfile(im_file_scl):\n",
    "\n",
    "            # Open SCL and change invalid pixels categories by NaN\n",
    "            src = rasterio.open(scl_file, \"r\")\n",
    "\n",
    "            # Read file as numpy array\n",
    "            SCL = src.read(1)\n",
    "            src.close()\n",
    "\n",
    "            # print('Scene Classification map')\n",
    "            # show(SCL, cmap='Set3')\n",
    "\n",
    "            SCL = SCL.astype(float)\n",
    "\n",
    "\n",
    "            SCL[SCL == 0] = np.nan    \n",
    "            SCL[SCL == 1] = np.nan    \n",
    "            SCL[SCL == 2] = 1        \n",
    "            SCL[SCL == 3] = np.nan    \n",
    "            SCL[SCL == 4] = 1         \n",
    "            SCL[SCL == 5] = 1         \n",
    "            SCL[SCL == 6] = 1      \n",
    "            SCL[SCL == 7] = 1      \n",
    "            SCL[SCL == 8] = np.nan    \n",
    "            SCL[SCL == 9] = np.nan    \n",
    "            SCL[SCL == 10] = np.nan  \n",
    "            SCL[SCL == 11] = np.nan   \n",
    "            # Open file\n",
    "            src = rasterio.open(im_file, \"r\")\n",
    "\n",
    "            # Read file as numpy array\n",
    "            im = src.read(1)\n",
    "\n",
    "            # Update metadata\n",
    "            profile = src.profile\n",
    "            profile.update(\n",
    "                dtype=rasterio.int16,  # Set to int16 it is lighter than float\n",
    "                nodata=nodata_val,  # Set nodata value in metadata\n",
    "                compress=\"lzw\",\n",
    "            )  # Compression option\n",
    "\n",
    "            # Mask image reflectance with SCL\n",
    "            im_SLC = im[0:1146,0:1270] * SCL\n",
    "\n",
    "            # Change numpy NaN by nodata_val (e.g. -10000)\n",
    "            im_SLC[np.isnan(im_SLC)] = nodata_val\n",
    "\n",
    "            # Change the array's type : from float to integer 16\n",
    "            im_SLC = im_SLC.astype(np.int16)\n",
    "\n",
    "            # Write image\n",
    "            dst = rasterio.open(im_file_scl, \"w\", **profile)\n",
    "            dst.write(im_SLC, 1)\n",
    "\n",
    "            # Close rasterio objects\n",
    "            src.close()\n",
    "            dst.close()\n",
    "\n",
    "            print(f\"A new raster file is created : {im_file_scl}\")\n",
    "\n",
    "    print(\"--> SCL is applied on all images !\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "band = 'B4'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "\n",
    "im_file_clip = sorted(glob(f'{rasters_path}{band}/*.tif'))[8]\n",
    "\n",
    "src = rasterio.open(im_file_clip, \"r\")\n",
    "rasterio.plot.show(src, ax=ax1, cmap='Greys_r', title=\"Before masking the cloudy pixels\")\n",
    "\n",
    "\n",
    "im_file_scl = sorted(glob(f'{rasters_path}{band}_MASKED_SEN2COR/*.tif'))[8]\n",
    "\n",
    "src = rasterio.open(im_file_scl, \"r\")\n",
    "\n",
    "rasterio.plot.show(src, ax=ax2, cmap='Greys_r', title=\"After having masked the cloudy pixels\")\n",
    "\n",
    "plt.box(False)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of the folium library to display raster or vector data \n",
    "\n",
    "The folium library is designed to display geo-referenced data in an interactive way in the form of leaflets. Thanks to this type of display, different basemaps (OpenStreetMap, Google Satellite Imagery and plenty others)  can be used and several raster layers can be overlaid, activated or deactivated through the interface.\n",
    "\n",
    "In the next cell, the first date of the time serie of the spectral band 4 (red) is displayed. The raster layer can be deactivated using the layer manager button on the top right corner of the leaflet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualisation of the rasters using folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_list = [sorted(red_list)[5], sorted(green_list)[5], sorted(blue_list)[5]]\n",
    "bands = [\"B2\", \"B3\", \"B4\"]\n",
    "\n",
    "m = folium.Map(\n",
    "    [50.58634675562977, 5.038316875760848],\n",
    "    zoom_start=10,\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name = 'Satellite'\n",
    ")\n",
    "for band, name in zip(clipped_list, bands):\n",
    "    with rasterio.open(band) as src:\n",
    "\n",
    "        vmin, vmax = np.nanpercentile(src.read(1), (10,90 )) \n",
    "        im = src.read(1).astype(float)\n",
    "\n",
    "        bounds = src.bounds\n",
    "        bottom = bounds.bottom \n",
    "        left = bounds.left\n",
    "        right = bounds.right\n",
    "        top = bounds.top\n",
    "\n",
    "        transformer = Transformer.from_crs(\"epsg:32631\", \"epsg:4326\")\n",
    "\n",
    "        x1, y1 = left, bottom\n",
    "        x3, y3 = right, top\n",
    "\n",
    "        x2, y2 = transformer.transform(x1, y1)\n",
    "        x4, y4 = transformer.transform(x3, y3)\n",
    "\n",
    "        im_loc = f\"{output_path}ROI_example_{name}.png\"\n",
    "\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        plt.imsave(im_loc, im, vmin=vmin, vmax=vmax, cmap=\"Greys_r\")\n",
    "\n",
    "        img = folium.raster_layers.ImageOverlay(\n",
    "            name=name,\n",
    "            image=im_loc,\n",
    "            bounds=[[x2-0.008, y2-0.006], [x4-0.008, y4-0.006]],\n",
    "            opacity=1,\n",
    "            interactive=True,\n",
    "            cross_origin=False,\n",
    "            zindex=1,\n",
    "        )\n",
    "\n",
    "        img.add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Computation of the mean surface reflectance value for each date \n",
    "\n",
    "The mean reflectance of the pixels is computed for every invariant target polygon, every date, and the 4 bands. This will allow to assess the temporal consistency of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = invariant_gdf.geometry.values\n",
    "geoms = [mapping(x) for x in geoms]\n",
    "#band = 'B4'\n",
    "\n",
    "band_array = []\n",
    "for band in bands:\n",
    "    stat_mat = []\n",
    "    \n",
    "    for im in sorted(glob(f\"{bands_path}/*.data/{band}.img\")):\n",
    "        lai_vec = []\n",
    "        for polygon in geoms:\n",
    "\n",
    "            with rasterio.open(im) as src:\n",
    "\n",
    "                out_image, out_transform = rasterio.mask.mask(\n",
    "                    src, [polygon], crop=True, nodata=-10000\n",
    "                )\n",
    "                out_image = out_image.astype(float)\n",
    "                out_image[(out_image > 55500.0) |(out_image == -10000.0)] = np.nan\n",
    "\n",
    "                out_image = out_image/10000\n",
    "                #print(np.nanmin(out_image),np.nanmean(out_image),np.nanmax(out_image))\n",
    "                lai_vec.append(np.nanmean(out_image))\n",
    "        stat_mat.append(lai_vec)\n",
    "    print(f\"The band {band} has been processed\")\n",
    "    band_array.append(stat_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Count of the number of valid dates for each polygon\n",
    "\n",
    "For each polygon, the number of dates where valid pixels can be used is counted. (Here the images are cloud free and not masked so all the dates will be valid, in other contexts, no-data values could make certain dates unusable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(invariant_gdf[\"geometry\"])):\n",
    "    type = np.array(invariant_gdf[\"TYPE\"])[j]\n",
    "    polygon = [i[j] for i in band_array[2]]\n",
    "    cnt = np.count_nonzero(np.isnan(polygon))\n",
    "    print(\n",
    "        f\"There are {cnt} non valid dates and {len(polygon)-cnt} valid dates for the polygon of the {type} \"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Plot of the surface reflectance time series for the blue, green and red bands and outlier detection\n",
    "\n",
    "\n",
    " The time series of surface reflectance in the red band from pixels of the 5 different land cover types are plotted.\n",
    "\n",
    "This section will focus on the analysis of the time series of each polygon. To detect the outliers, the median of the time series will first be calculated. Then, a threshold deviation from this median will be defined, and any date whose reflectance for a given pixel exceeds the threshold will be transformed into no data. \n",
    "\n",
    "The defined deviation for this notebook is 0.01, meaning that all values of the time series for each polygon exceeding the sum of the median and the deviation or being smaller than the difference between the median and the deviation are considered as an invalid date. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable ```outliers_dates_mat``` will store the dates detected as outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_dates_mat = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis of the blue band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime.strptime(x[-46:-38],'%Y%m%d' )for x in blue_list]\n",
    "\n",
    "\n",
    "threshold = 0.015\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "types = invariant_gdf[\"TYPE\"]\n",
    "for j, k, l in zip(\n",
    "    range(len(invariant_gdf[\"geometry\"])), [axs[0, 1], axs[0, 0], axs[1, 1], axs[1, 0],axs[2,0]], types\n",
    "):\n",
    "\n",
    "    ts = [i[j] for i in band_array[0]]\n",
    "    median = [np.nanmean(ts)]*len(ts)\n",
    "    max_dev = [i + threshold for i in median]\n",
    "    min_dev = [i - threshold for i in median]\n",
    "\n",
    "    outliers = [[count,i] for count,i in enumerate(ts) if i >= max_dev[0] or i <= min_dev[0]]\n",
    "    outliers_dates = [dates[i[0]].strftime(\"%d/%m/%Y\") for i in outliers]\n",
    "\n",
    "\n",
    "\n",
    "    markers_on = np.argwhere(~np.isnan(ts))\n",
    "    markers_on = [i[0] for i in markers_on]\n",
    "\n",
    "    if len(outliers) > 0 and l!= 'quarry' and l != 'warehouse roof':\n",
    "        print(f'there are {len(outliers)} outliers detected on the invariant surface {l}')    \n",
    "        print(f'Outliers dates : {outliers_dates}')\n",
    "        outliers_dates_mat.append(outliers_dates)\n",
    "        \n",
    "    k.plot(dates, ts, \"bD\", markevery=markers_on)\n",
    "    k.plot(dates,median,  linestyle='--',color = 'green',label = 'Median reflectance')\n",
    "    k.plot(dates,max_dev,  linestyle='--',color = 'black',label = 'Median + threshold')\n",
    "    k.plot(dates,min_dev,  linestyle='-.',color = 'black',label = 'Median - threshold')\n",
    "\n",
    "    \n",
    "    k.set_ylim()\n",
    "    k.title.set_text(\n",
    "        f\"{str(l)}\"\n",
    "    )\n",
    "    k.grid(True)\n",
    "    k.legend()\n",
    "    fig.suptitle('Time series of the mean surface \\n reflectance in the blue band of \\n 5 types of polygons',fontweight=\"bold\",y = 1.1)\n",
    "    axs[2,1].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis of the green band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime.strptime(x[-46:-38],'%Y%m%d' )for x in green_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "types = invariant_gdf[\"TYPE\"]\n",
    "for j, k, l in zip(\n",
    "    range(len(invariant_gdf[\"geometry\"])), [axs[0, 1], axs[0, 0], axs[1, 1], axs[1, 0],axs[2,0]], types\n",
    "):\n",
    "\n",
    "    ts = [i[j] for i in band_array[1]]\n",
    "    \n",
    "    median = [np.nanmean(ts)]*len(ts)\n",
    "    max_dev = [i + threshold for i in median]\n",
    "    min_dev = [i - threshold for i in median]\n",
    "    outliers = [[count,i] for count,i in enumerate(ts) if i >= max_dev[0] or i <= min_dev[0]]\n",
    "    outliers_dates = [dates[i[0]].strftime(\"%d/%m/%Y\") for i in outliers]\n",
    "\n",
    "\n",
    "    if len(outliers) > 0 and l!= 'quarry' and l != 'warehouse roof':\n",
    "        print(f'there are {len(outliers)} outliers detected on the invariant surface {l}')    \n",
    "        print(f'Outliers dates : {outliers_dates}')\n",
    "        outliers_dates_mat.append(outliers_dates)\n",
    "\n",
    "    markers_on = np.argwhere(~np.isnan(ts))\n",
    "    markers_on = [i[0] for i in markers_on]\n",
    "    \n",
    "    k.plot(dates, ts, \"gD\", markevery=markers_on)\n",
    "    k.plot(dates,median,  linestyle='--',color = 'green',label = 'Median reflectance')\n",
    "    k.plot(dates,max_dev,  linestyle='--',color = 'black',label = 'Median + threshold')\n",
    "    k.plot(dates,min_dev,  linestyle='-.',color = 'black',label = 'Median - threshold')\n",
    "\n",
    "\n",
    "\n",
    "    k.set_ylim()\n",
    "    k.title.set_text(\n",
    "        f\"{str(l)}\"\n",
    "    )\n",
    "    k.grid(True)\n",
    "    k.legend()\n",
    "    fig.suptitle('Time series of the mean surface \\n reflectance in the green band of \\n 5 types of polygons',fontweight=\"bold\",y = 1.1)\n",
    "    axs[2,1].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis of the red band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime.strptime(x[-46:-38],'%Y%m%d' )for x in red_list]\n",
    "\n",
    "\n",
    "threshold = 0.015\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "types = invariant_gdf[\"TYPE\"]\n",
    "for j, k, l in zip(\n",
    "    range(len(invariant_gdf[\"geometry\"])), [axs[0, 1], axs[0, 0], axs[1, 1], axs[1, 0],axs[2,0]], types\n",
    "):\n",
    "\n",
    "    ts = [i[j] for i in band_array[2]]\n",
    "    median = [np.nanmean(ts)]*len(ts)\n",
    "    max_dev = [i + threshold for i in median]\n",
    "    min_dev = [i - threshold for i in median]\n",
    "    outliers = [[count,i] for count,i in enumerate(ts) if i >= max_dev[0] or i <= min_dev[0]]\n",
    "    outliers_dates = [dates[i[0]].strftime(\"%d/%m/%Y\") for i in outliers]\n",
    "    \n",
    "    if len(outliers) > 0 and l!= 'quarry' and l != 'warehouse roof':\n",
    "        print(f'there are {len(outliers)} outliers detected on the invariant surface {l}')    \n",
    "        print(f'Outliers dates : {outliers_dates}')\n",
    "        #outliers_dates_mat.append(outliers_dates)\n",
    "\n",
    "\n",
    "    markers_on = np.argwhere(~np.isnan(ts))\n",
    "    markers_on = [i[0] for i in markers_on]\n",
    "    k.plot(dates, ts, \"rD\", markevery=markers_on)\n",
    "    k.plot(dates,median,  linestyle='--',color = 'green',label = 'Median reflectance')\n",
    "    k.plot(dates,max_dev,  linestyle='--',color = 'black',label = 'Median + threshold')\n",
    "    k.plot(dates,min_dev,  linestyle='-.',color = 'black',label = 'Median - threshold')\n",
    "\n",
    "\n",
    "\n",
    "    k.set_ylim()\n",
    "    k.title.set_text(\n",
    "        f\"{str(l)}\"\n",
    "    )\n",
    "    k.grid(True)\n",
    "    k.legend()\n",
    "    fig.suptitle('Time series of the mean surface \\n reflectance in the red band of \\n 5 types of polygons',fontweight=\"bold\",y = 1.15)\n",
    "    axs[2,1].set_visible(False)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in outliers_dates_mat for item in sublist]\n",
    "count =  Counter(flat_list)\n",
    "count = count.most_common()\n",
    "\n",
    "for i in count:\n",
    "    print(f'the date {i[0]} has been detected as an outlier {i[1]} time(s) over invariants surfaces and spectral bands')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LAI time series analysis: intra- and inter-field crop growth quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Vizualisation \n",
    "\n",
    "### The extent of the shapefile containing the corn parcels is computed to display the area of interest\n",
    "\n",
    "This extent can also be used to clip images and reduce computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots(figsize = (20,20))\n",
    "\n",
    "extent = box(*roi_gdf.geometry.total_bounds)\n",
    "extent_gdf = geopandas.GeoDataFrame(index=[0], crs=\"epsg:32631\", geometry=[extent])\n",
    "\n",
    "extent_gdf.plot(ax = ax, facecolor=\"none\", edgecolor=\"red\", linewidth=4)\n",
    "cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik, crs=roi_gdf.crs.to_string())\n",
    "ax.set_title('Shapefile extent')\n",
    "\n",
    "#extent_gdf.to_file(filename= f\"{work_path}extent.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of LAI value ranges for the time series\n",
    "\n",
    "The single-band rasters are plotted, slightly augmenting the contrast for visualization purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = [lai_list[15],lai_list[16],lai_list[20]]\n",
    "print(f'the image list contains the following images : {[os.path.basename(i) for i in im_list]}')\n",
    "\n",
    "print(f'the dates of the image list are : {np.sort(dates)[15]}, {np.sort(dates)[16]} and {np.sort(dates)[20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bands = [\"LAI_1\", \"LAI_2\", \"LAI_3\"]\n",
    "\n",
    "m = folium.Map(\n",
    "    [50.58634675562977, 5.038316875760848],\n",
    "    zoom_start=10,\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name = 'Satellite'\n",
    ")\n",
    "for band, name in zip(im_list, bands):\n",
    "    with rasterio.open(band) as src:\n",
    "\n",
    "        vmin, vmax = np.nanpercentile(src.read(1), (6, 94)) \n",
    "        im = src.read(1).astype(float)\n",
    "\n",
    "        bounds = src.bounds\n",
    "        bottom = bounds.bottom \n",
    "        left = bounds.left\n",
    "        right = bounds.right\n",
    "        top = bounds.top\n",
    "\n",
    "        transformer = Transformer.from_crs(\"epsg:32631\", \"epsg:4326\")\n",
    "\n",
    "        x1, y1 = left, bottom\n",
    "        x3, y3 = right, top\n",
    "\n",
    "        x2, y2 = transformer.transform(x1, y1)\n",
    "        x4, y4 = transformer.transform(x3, y3)\n",
    "\n",
    "        im_loc = f\"{output_path}ROI_example_{name}.png\"\n",
    "\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        plt.imsave(im_loc, im, vmin=vmin, vmax=vmax, cmap=\"Greys_r\")\n",
    "\n",
    "        img = folium.raster_layers.ImageOverlay(\n",
    "            name=name,\n",
    "            image=im_loc,\n",
    "            bounds=[[x2-0.008, y2-0.006], [x4-0.008, y4-0.006]],\n",
    "            opacity=1,\n",
    "            interactive=True,\n",
    "            cross_origin=False,\n",
    "            zindex=1,\n",
    "        )\n",
    "\n",
    "        img.add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the extent of the region of interest on a LAI multi-temporal color composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_list = im_list[0:3]\n",
    "for i in rgb_list:\n",
    "    print(f'The band {i[-6:]} can be added to the composite')\n",
    "rgb_array = []\n",
    "for image in rgb_list:\n",
    "    with rasterio.open(image) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(\n",
    "            src, extent_gdf.geometry, all_touched=True, crop=True\n",
    "        )\n",
    "\n",
    "        rgb_array.append(out_image)\n",
    "\n",
    "rgb_stack = np.vstack(rgb_array)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ep.plot_rgb(\n",
    "    rgb_stack,\n",
    "    rgb=(2, 1, 0),\n",
    "    ax=ax,\n",
    "    title=\"LAI multi-temporal color composite at 10m : 15th May (Red), 1st June (Green), 14 September (Blue)\",\n",
    "    stretch=True,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maize_gdf = roi_gdf[roi_gdf['CROP_NAME'] == 'Maize (for livestock)']\n",
    "\n",
    "print(f'There are {len(maize_gdf)} maize parcels in the shapefile')\n",
    "maize_gdf = maize_gdf.sample(frac = 0.20,random_state = 1)\n",
    "print(f'There are {len(maize_gdf)} selected maize parcels ')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots( figsize=(20, 20))\n",
    "\n",
    "axs.set_title(\"Visualization of the parcels\", fontsize=25)\n",
    "\n",
    "\n",
    "maize_gdf.plot(\n",
    "    ax=axs,\n",
    "    facecolor=None,\n",
    "    edgecolor=\"red\",\n",
    "    alpha=0.8,\n",
    "    lw=3\n",
    ")\n",
    "\n",
    "cx.add_basemap(axs, source=cx.providers.Esri.WorldImagery, crs=roi_gdf.crs.to_string())\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Computation of the mean LAI value at parcel level for each date of the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the raster containing the cloud-free LAI time series. \n",
    "Then the computation of the mean LAI by date and by parcel takes place in four successive steps: \n",
    "\n",
    "1. First the polygons of all parcels are stored in a variable\n",
    "2. For each polygon, a mask is created and used to mask all the other pixels than the ones included in the polygon\n",
    "3. Finally, the mean LAI on this parcel is computed for each date and the result is stored in a vector (here ```lai_vec```)\n",
    "4. The vectors (```lai_vec```) storing the LAI time series of each parcel are stored in a matrix (```lai_mat```) which will later be converted do a table (here called a pandas Dataframe)\n",
    "\n",
    "This step can take some time to compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_raster_list = sorted(glob(f\"{lai_path}/*.data/lai.img\"))\n",
    "stacked_raster_array,transform  = es.stack(LAI_raster_list)\n",
    "stacked_raster_path = f'{output_path}/stacked_LAI.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(stacked_raster_path, 'w', **transform) as dst:\n",
    "    dst.write(stacked_raster_array)\n",
    "    \n",
    "geoms = maize_gdf.geometry.values\n",
    "\n",
    "geoms = [mapping(x) for x in geoms]\n",
    "\n",
    "lai_mat = []\n",
    "for parcel in geoms:\n",
    "    with rasterio.open(f'{output_path}/stacked_LAI.tif') as src:\n",
    "        lai_vec = []\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [parcel], crop=True, nodata=-32768)\n",
    "        \n",
    "        out_image = np.where(out_image==-32768, np.nan, out_image)\n",
    "        for date in range(np.shape(out_image)[0]):\n",
    "            \n",
    "            lai_vec.append(np.nanmean(out_image[date, :, :]))\n",
    "            \n",
    "        lai_mat.append(lai_vec)\n",
    "print(f'The matrix contains {len(lai_mat)} time series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a dataframe containing the time series computed above\n",
    "Once the mean LAI is computed for each parcel and for each date, the data is stored in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lai_mat)\n",
    "lai_df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The first image of the list is {os.path.basename(sorted(glob(f\"{lai_path}/*.data/lai.img\"))[0])}')\n",
    "dates = [datetime.strptime(x[-47:-39],'%Y%m%d' )for x in sorted(glob(f\"{lai_path}/*.data/lai.img\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes of the dataframe are set as the dates of each images and the column names as the parcel IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lai_df.index = dates\n",
    "date_to_remove = lai_df.index[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lai_df.index = dates\n",
    "lai_df.columns = maize_gdf.index\n",
    "lai_unsorted = lai_df\n",
    "lai_df = lai_df.sort_index()\n",
    "\n",
    "lai_df = lai_df.drop(date_to_remove)\n",
    "\n",
    "display(lai_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotly library is used to plot the LAI time series of all the parcels. The mean, 25th percentile, and 75th percentile are also added to the plot. \n",
    "This library can be used in a more interactive way than matplotlib and allows to look at individual profiles. \n",
    "* Double clicking on any element of the legend removes all the lines on the plot, and clicking on single legend elements makes them visible again. \n",
    "* Plotly also allows to make screenshots and zoom on particular areas of the plot using the menu on the top-right corner of the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    "for col,i in zip(lai_df.columns,range(len(lai_df.columns))):\n",
    "    fig.add_trace(go.Scatter(x=lai_df.index, y=lai_df[col].values,\n",
    "                                 name = col,\n",
    "                                 mode = 'lines'))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x = lai_df.index,y = lai_df.median(axis=1),line_color = 'black', line = dict(width=4),name = 'mean'))\n",
    "fig.add_trace(go.Scatter(x = lai_df.index,y = lai_df.quantile(q= 0.25,axis=1),line_color = 'firebrick',  line = dict(width=4),name = '25-percentile'))\n",
    "fig.add_trace(go.Scatter(x = lai_df.index,y = lai_df.quantile(q= 0.75,axis=1),line_color = 'firebrick', line = dict(width=4),name = '75-percentile'))\n",
    "fig.update_layout(legend_traceorder=\"reversed\")\n",
    "\n",
    "\n",
    "fig.update_layout(height=800, width=800,title = 'LAI time series of all the Maize parcels in the area of interest')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on the corn growth cycle \n",
    "In order to consider the growth cycle of the corn sowed early May, and harvested in September–October, the beginning date of the time series will be set to the first of May and the end date to the 15th of November.\n",
    "\n",
    "The dataframe is also displayed, each column representing a corn parcel and each row a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lai_df_reduced = lai_df[(lai_df.index > '2020-05-01') & (lai_df.index < '2020-11-15')]\n",
    "dates_before = len(lai_df[(lai_df.index <= '2020-05-01') ])\n",
    "display(lai_df[(lai_df.index <= '2020-05-01') ])\n",
    "fig = go.Figure() \n",
    "\n",
    "for col,i in zip(lai_df_reduced.columns,range(len(lai_df_reduced.columns))):\n",
    "    fig.add_trace(go.Scatter(x=lai_df_reduced.index, y=lai_df_reduced[col].values,\n",
    "                                 name = col,\n",
    "                                 mode = 'lines'))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x = lai_df_reduced.index,y = lai_df_reduced.mean(axis=1),line_color = 'black', line = dict(width=4),name = 'mean'))\n",
    "fig.add_trace(go.Scatter(x = lai_df_reduced.index,y = lai_df_reduced.quantile(q= 0.25,axis=1),line_color = 'firebrick',  line = dict(width=4),name = '25-percentile'))\n",
    "fig.add_trace(go.Scatter(x = lai_df_reduced.index,y = lai_df_reduced.quantile(q= 0.75,axis=1),line_color = 'firebrick', line = dict(width=4),name = '75-percentile'))\n",
    "fig.update_layout(legend_traceorder=\"reversed\")\n",
    "\n",
    "\n",
    "fig.update_layout(height=800, width=800,title = 'LAI time series of all the Maize parcels in the area of interest between may and november')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Inter-field analysis of the LAI temporal profile\n",
    "The average maize profile corresponds here to the normal crop growth condition.  \n",
    "\n",
    "* First, the area under each LAI curve is computed for the whole season to quantify the crop growth condition in one single metric. \n",
    "* Second, for all the maize parcels of the region of interest, the distribution of these integrated LAI is then presented and quantiles are calculated.\n",
    "* Third, 5 categories are defined based on quantiles (i.e. percentile between 15 and 20 ,percentile 40, percentile 60, percentile 80). Those categories are displayed on the histogram and correspond respectively to very poor, poor, medium, good, and very good growth conditions. Based on the above graph, temporal profiles hardly corresponding to regular corn crops (e.g. very low value until August) should not be considered for the inter-field analysis and are assumed to belong to the lowest percentiles (0-15).\n",
    "* Finally, parcels are classified according to these categories and this information is written as an attribute in a new shapefile to examine using QGIS. \n",
    "\n",
    "The trapezoidal integretion method is used to compute the area under each curve (auc) which are stored in the ```auc``` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_vec = [(np.trapz(parcel_timeserie)) for parcel_timeserie in lai_df_reduced.transpose().values.tolist()]\n",
    "auc_df = pd.DataFrame(auc_vec)\n",
    "\n",
    "auc = [np.array(x)[0] for x in np.array(auc_df)]\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df.columns = ['Area Under Curve']\n",
    "fig = px.histogram(auc_vec,nbins = 8,title = 'Histogram of the areas under the curves computed for all maize parcels')\n",
    "fig.show()\n",
    "\n",
    "lai_df_reduced_transposed = lai_df_reduced.transpose()\n",
    "auc_df.index = lai_df_reduced_transposed.index\n",
    "\n",
    "display(auc_df)\n",
    "#display(lai_df_reduced_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of 5 dataframes containing the time series of each category (very low, low, medium, high, very high)\n",
    "\n",
    "The dataframes will later be concatenated to obtain a single table containing the time series and their crop-growth quality assessment computed a few cells earlier.\n",
    "The 'very low' dataframe is displayed as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") #\n",
    "\n",
    "very_low_df = lai_df_reduced_transposed[(auc_df['Area Under Curve']> np.nanpercentile(auc,15)) & (auc_df['Area Under Curve'] < np.nanpercentile(auc,20))] \n",
    "very_low_df['Quality']= 'very low'\n",
    "low_df = lai_df_reduced_transposed[(auc_df['Area Under Curve'] > np.nanpercentile(auc,20)) &(auc_df['Area Under Curve'] < np.nanpercentile(auc,40))] \n",
    "low_df['Quality']= 'low'\n",
    "\n",
    "medium_df = lai_df_reduced_transposed[(auc_df['Area Under Curve'] > np.nanpercentile(auc,40)) &(auc_df['Area Under Curve'] < np.nanpercentile(auc,60))]\n",
    "medium_df['Quality']= 'medium'\n",
    "\n",
    "high_df = lai_df_reduced_transposed[(auc_df['Area Under Curve'] > np.nanpercentile(auc,60)) &(auc_df['Area Under Curve'] < np.nanpercentile(auc,80))]\n",
    "high_df['Quality']= 'high'\n",
    "very_high_df = lai_df_reduced_transposed[(auc_df['Area Under Curve'] > np.nanpercentile(auc,80)) &(auc_df['Area Under Curve'] < np.nanpercentile(auc,100))] \n",
    "very_high_df['Quality']= 'very high'\n",
    "\n",
    "display(very_low_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of the dataframes into one dataframe in which each parcel (columns) has row values corresponding to the mean LAI at each date and one  quality assessment attribute as last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenation = pd.concat([medium_df, very_high_df,high_df,low_df,very_low_df])\n",
    "final_df = concatenation.transpose()\n",
    "#display(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the time series for each parcel are plotted with a line-color varying with the quality assessment: \n",
    " \n",
    " |color|Qality|\n",
    " |---|---|\n",
    " |Red lines | very low |\n",
    " |Orange lines| low  |\n",
    " |Yellow lines | medium  |\n",
    " | Green lines | high  |\n",
    " |Blue lines | very high  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {'very low':'red','low':'orange','medium':'yellow','high':'green','very high':'blue'} \n",
    "colors = [cmap[x] for x in final_df.transpose()[\"Quality\"]]\n",
    "\n",
    "fig = go.Figure()\n",
    "for col,i in zip(final_df.columns,range(len(final_df.columns))):\n",
    "    fig.add_trace(go.Scatter(x=final_df.index[:-1], y=final_df[col].values[:-1],\n",
    "                                 name = col,\n",
    "                                 mode = 'lines',\n",
    "                                 line_color=colors[i]))\n",
    "fig.update_layout(height=800, width=800,title = 'Time-filtered time series with colors according to the crop growth quality assessment')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table join using indices between the final dataframe containing the information regarding the assessment of crop growth quality and the partial Geodataframe containing the parcels.\n",
    "\n",
    "\n",
    "Before the table join: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_join = final_df.transpose()['Quality']\n",
    "display(to_join)\n",
    "display(maize_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the table join: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf = roi_gdf.filter(items = to_join.index, axis=0)\n",
    "new_gdf['Quality'] = to_join\n",
    "display(new_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save of the file as a shapefile that can be further explored in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "new_gdf_path = f'{work_path}/maize_LAI_quality_assessment.shp'\n",
    "\n",
    "if not os.path.isfile(new_gdf_path):\n",
    "    new_gdf.to_file(new_gdf_path)\n",
    "else:\n",
    "    print('the shp already exists')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Intra-field variability analysis at the peak of the LAI on a given parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of parcels containing 3 parcels of very-low, medium, and very high parcels is first selected. Then, the date where the LAI is at its highest point is computed for each parcel. The parcels are then plotted on their maximal LAI day for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_low_subset = new_gdf[new_gdf['Quality']=='very low'].iloc[0:3,:]\n",
    "medium_subset = new_gdf[new_gdf['Quality']=='medium'].iloc[[4,7,8],:]\n",
    "very_high_subset = new_gdf[new_gdf['Quality']=='very high'].iloc[[0,2,4],:]\n",
    "\n",
    "total_subset = pd.concat([very_low_subset,medium_subset,very_high_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = geopandas.GeoDataFrame(lai_df_reduced.filter(items = total_subset.index, axis=1))\n",
    "max_values = subset.idxmax(axis=0).values\n",
    "print(max_values)\n",
    "indexes = pd.DataFrame(subset).idxmax(axis=0)\n",
    "positions = [lai_unsorted.index.get_loc(i) for i in indexes]\n",
    "print(positions)\n",
    "display(subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'the max LAI of the first very-low labelled parcel is obtained at the date  {str(max_values[0])[:10]} of the time series')\n",
    "print(f'the max LAI of the first medium labelled parcel is obtained at the date  {str(max_values[1])[:10]} of the time series')\n",
    "print(f'the max LAI of the first very-high labelled parcel is obtained at the date  {str(max_values[2])[:10]} of the time series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of three parcels of the very-low, medium, and very high categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(3,3,figsize = (10,10),gridspec_kw={'width_ratios': [1, 1, 1]})\n",
    "geoms = total_subset.geometry.values\n",
    "geoms = [mapping(x) for x in geoms]\n",
    "cols = ['Very low \\n quality parcels','Medium \\n quality parcels','Very high \\n quality parcels']\n",
    "axes = [axs[0,0],axs[1,0],axs[2,0],axs[0,1],axs[1,1],axs[2,1],axs[0,2],axs[1,2],axs[2,2]]\n",
    "for parcel,date,i,j in zip(geoms,positions,axes,range(9)):\n",
    "    with rasterio.open(stacked_raster_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [parcel], crop=True, nodata=-32768)\n",
    "        out_image = np.where(out_image==-32768, np.nan, out_image)\n",
    "        output = out_image[date, :, :]\n",
    "        im = i.imshow(output,cmap = 'BrBG',vmin = 0,vmax = 6)\n",
    "        fig.colorbar(im,ax = i,fraction=0.046, pad=0.04,label = 'LAI' )\n",
    "        i.set_title(f'parcel {subset.columns[j]}', y=1.05, fontsize=18)\n",
    "        \n",
    "for ax, col in zip(axs[0], cols):\n",
    "    ax.annotate(col, xy=(0.5, 1.25), xytext=(0, 15),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, bottom=0.1)\n",
    "fig.suptitle('Plot of three parcels of very-low, medium and very high categories',y = 1.15)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
